{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c061611",
   "metadata": {},
   "source": [
    "# Associating collections with HOSS.\n",
    "\n",
    "This notebook describes the steps required to associate a new collection with the [Harmony OPeNDAP SubSetter (HOSS)](https://github.com/nasa/harmony-opendap-subsetter), and provides example requests that can be performed to ensure the collection is compatible with HOSS.\n",
    "\n",
    "## Contact:\n",
    "\n",
    "There are a number of NASA EOSDIS Slack channels dedicated to either HOSS or Harmony:\n",
    "\n",
    "* `#variable_subsetter` - A HOSS-specific channel.\n",
    "* `#harmony` - A place for all things Harmony.\n",
    "* `#harmony-service-providers` - A place for backend service specific Harmony discussions.\n",
    "\n",
    "Alternatively, reach out via email to: <owen.m.littlejohns@nasa.gov> or <david.p.auty@nasa.gov>.\n",
    "\n",
    "## Notebook prerequisites:\n",
    "\n",
    "This Jupyter notebook assumes it is running in an environment containing the following Python packages:\n",
    "\n",
    "* [harmony-py](https://github.com/nasa/harmony-py) - used to make requests against Harmony.\n",
    "* [notebook](https://pypi.org/project/notebook/) - used to run this notebook.\n",
    "* [netCDF4](https://pypi.org/project/netCDF4/) - used by `xarray` to open NetCDF-4 files.\n",
    "* [xarray](https://pypi.org/project/xarray/) - used to verify output\n",
    "\n",
    "This notebook also assumes that an end-user has a `.netrc` file configured on their local machine, which should contain an entry for the Earthdata Login environment that will be used for test requests. Such an entry will look like:\n",
    "\n",
    "```\n",
    "machine urs.earthdata.nasa.gov\n",
    "    login <EDL username>\n",
    "    password <EDL password>\n",
    "```\n",
    "\n",
    "## Collection prerequisites:\n",
    "\n",
    "HOSS is primarily designed to perform variable, temporal, bounding box spatial and shape file spatial subsetting on gridded collections (L3/L4). It is expected that these collections contain 1-D grid dimension variables metadata adhering to the [NetCDF Climate and Forecast (CF) metadata conventions](http://cfconventions.org/).\n",
    "\n",
    "The requirements of HOSS include:\n",
    "\n",
    "* The collection has been ingested to the cloud, via either Cumulus, or within the UAT EEDTEST provider.\n",
    "* Each granule in the collection is accessible via OPeNDAP, with a sidecar `.dmrpp` file and an OPeNDAP related URL in its UMM-G record.\n",
    "* All gridded variables with the source data file contain named dimensions, which have accompanying 1-D dimension variables within the granule.\n",
    "* Any variables that support gridded variables are indicated via the appropriate metadata attribute, conforming to the CF-Conventions. Examples include \"coordinates\", \"bounds\" and \"grid_mapping\".\n",
    "* [Projection-gridded collections must have a variable that encapsulates the Coordinate Reference System (CRS) of the granule](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.10/cf-conventions.html#grid-mappings-and-projections). Each science variable that uses this projected grid must have a \"grid_mapping\" metadata attribute that refers to this CRS variable.\n",
    "\n",
    "## Making a UMM-S to UMM-C association:\n",
    "\n",
    "The Common Metadata Repository (CMR) offers the ability to associate entities from different providers. For this reason, it is recommended that operators associate their collections to UMM-S records provided by the maintainers of HOSS. [This can be most easily achieved via the Metadata Management Tool](https://wiki.earthdata.nasa.gov/display/CMR/Metadata+Management+Tool+%28MMT%29+User%27s+Guide#MetadataManagementTool(MMT)User'sGuide-AssociateaServicewithoneormoreCollectionsformyprovider) ([MMT](mmt.earthdata.nasa.gov)).\n",
    "\n",
    "A collection will only need to be associated with a single UMM-S record:\n",
    "\n",
    "| Service Name                | Environment | UMM-S Concept ID     | What to associate with it                |\n",
    "|:----------------------------|:-----------:|:--------------------:|:-----------------------------------------|\n",
    "| SDS/HOSS Geographic         | Production  | S2164732315-XYZ_PROV | L3/L4 geographically gridded collections |\n",
    "| SDS/HOSS Projection-gridded | Production  | S2300730272-XYZ_PROV | L3/L4 projection-gridded collections     |\n",
    "| SDS/HOSS Geographic         | UAT         | S1240682712-EEDTEST  | L3/L4 geographically gridded collections |\n",
    "| SDS/HOSS Projection-gridded | UAT         | S1245117629-EEDTEST  | L3/L4 projection-gridded collections     |\n",
    "| sds-variable-subsetter      | UAT         | S1237976118-EEDTEST  | Non-gridded collections requiring variable subsetting |\n",
    "\n",
    "These records should be visible via a search of service records in the appropriate version of MMT (either production or UAT). If they do not show up, please contact the maintainers of HOSS via the `#variable_subsetter` channel in the NASA EOSDIS Slack workspace.\n",
    "\n",
    "Please note that Harmony makes use of the UAT instance of CMR in both its UAT _and_ SIT environment, as well as any local testing via Harmony-in-a-Box. Associating a collection to HOSS in UAT makes it also available for use with HOSS in SIT and locally.\n",
    "\n",
    "### What is the \"Variable Subsetter\"?\n",
    "\n",
    "The table above has a separate entry for a Variable Subsetter service. This was the initial name for HOSS, as the first version of the service only offered variable subsetting via OPeNDAP as a transformation option. More capabilities have been added to HOSS, including spatial and temporal subsetting. Currently, the Harmony UAT instance maintains an sds-variable-subsetter service, which uses the same Docker image as HOSS, but only accepts parameters that will define a variable subset. This service is retained for use with collections that are not gridded (non L3 or L4).\n",
    "\n",
    "Upon migration to the NASA open-source GitHub organisation, efforts were taken to name the service and associated artefacts with terms directly relating to HOSS, as this is the form of the service that is available in production and is primarily what data curators are interested in using.\n",
    "\n",
    "## Verifying the output:\n",
    "\n",
    "The following sections of this notebook assume that a UMM-C to UMM-S association has been added between the collection to be tested and the appropriate HOSS UMM-S record, as described above.\n",
    "\n",
    "Because collections vary in their variable content, the notebook below does not attempt to plot any output. Instead, consider using a tool like [Panoply](https://www.giss.nasa.gov/tools/panoply/download/) for visual verification of output.\n",
    "\n",
    "### Import required functions and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import replace\n",
    "\n",
    "from harmony import BBox, Client, Collection, Environment, Request\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702cf9e",
   "metadata": {},
   "source": [
    "### Configure the notebook to test the associated collection:\n",
    "\n",
    "The values in the following cells should be set as described. Example values for the GPM/IMERG half hourly precipitation collection have been entered as a guide.\n",
    "\n",
    "First, select the environment containing the collection. This should be `Environment.PROD`, `Environment.UAT` or `Environment.SIT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8408df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmony_environment = Environment.UAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f39dbb",
   "metadata": {},
   "source": [
    "Next enter the UMM-C concept ID for the collection that has been associated with HOSS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_concept_id = 'C1245618475-EEDTEST'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0536d0",
   "metadata": {},
   "source": [
    "Enter the name of a variable that is within each granule of the collection. This should be the full path to the variable. Note - for some files without hierarchy, the full path may not need a leading slash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9177fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_to_subset = '/Grid/precipitationCal'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0f667",
   "metadata": {},
   "source": [
    "Define a temporal range that should match at least one granule in the test collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_range = {'start': datetime(2020, 1, 1, 0, 0, 0),\n",
    "                  'stop': datetime(2020, 1, 31, 23, 59, 59)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb279c",
   "metadata": {},
   "source": [
    "Define a bounding box within the coverage of the collection data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ab516",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box = BBox(w=-50, s=30, e=-20, n=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1faca6",
   "metadata": {},
   "source": [
    "Finally, specify a path to a local GeoJSON file that defines a shape file for spatial subsetting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c1f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_file_path = 'shape_files/bermuda_triangle.geo.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056f67e",
   "metadata": {},
   "source": [
    "After this point, none of the remaining cells should need to be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5d157",
   "metadata": {},
   "source": [
    "### Set up a client with Harmony:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a308b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmony_client = Client(env=harmony_environment)\n",
    "collection = Collection(id=collection_concept_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3a00f",
   "metadata": {},
   "source": [
    "### Extract variable parent group, for `xarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75234fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_group = '/'.join(variable_to_subset.split('/')[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c532eb",
   "metadata": {},
   "source": [
    "### A variable subset:\n",
    "\n",
    "This request will limit the returned variables to the one specified as `variable_to_subset`. The output will also include any supporting variables required to make a valid output. These include 1-D dimension variable or bounds variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the request:\n",
    "variable_subset_request = Request(collection=collection, variables=[variable_to_subset], max_results=1)\n",
    "\n",
    "# Submit the request and download the results\n",
    "variable_subset_job_id = harmony_client.submit(variable_subset_request)\n",
    "harmony_client.wait_for_processing(variable_subset_job_id, show_progress=True)\n",
    "variable_subset_outputs = [file_future.result()\n",
    "                           for file_future\n",
    "                           in harmony_client.download_all(variable_subset_job_id, overwrite=True)]\n",
    "\n",
    "replace(variable_subset_outputs[0], 'hoss_variable_subset.nc4')\n",
    "\n",
    "\n",
    "# Inspect the results:\n",
    "with xr.open_dataset('hoss_variable_subset.nc4', group=variable_group) as dataset:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c887694a",
   "metadata": {},
   "source": [
    "### A temporal subset:\n",
    "\n",
    "This request will limit the temporal range of the output to only include pixels that cover the specified range. If the collection that has been associated does not contain a temporal grid dimension, then this will only act as a filter on the granules identified in CMR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef61b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the request:\n",
    "temporal_subset_request = Request(collection=collection, temporal=temporal_range,\n",
    "                                  variables=[variable_to_subset], max_results=1)\n",
    "\n",
    "# Submit the request and download the results\n",
    "temporal_subset_job_id = harmony_client.submit(temporal_subset_request)\n",
    "harmony_client.wait_for_processing(temporal_subset_job_id, show_progress=True)\n",
    "temporal_subset_outputs = [file_future.result()\n",
    "                           for file_future\n",
    "                           in harmony_client.download_all(temporal_subset_job_id, overwrite=True)]\n",
    "\n",
    "replace(temporal_subset_outputs[0], 'hoss_temporal_subset.nc4')\n",
    "\n",
    "# Inspect the results:\n",
    "with xr.open_dataset('hoss_temporal_subset.nc4', group=variable_group) as dataset:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1964f82",
   "metadata": {},
   "source": [
    "### A bounding box spatial subset:\n",
    "\n",
    "This request will limit the spatial extent of the returned output. This request will be fulfilled differently depending on the UMM-S record associated with the data. This can be observed via the `/workflow-ui` endpoint of Harmony.\n",
    "\n",
    "* SDS/HOSS Geographic: Will call:\n",
    "  * `query-cmr` to filter granules to those with matching spatial coverage.\n",
    "  * `ghcr.io/nasa/harmony-opendap-subsetter` to perform HOSS operations and extract a rectangular portion of the longitude latitude grid. This will match the bounding box.\n",
    "* SDS/HOSS Projection-gridded:\n",
    "  * `query-cmr` to filter granules to those with matching spatial coverage.\n",
    "  * `ghcr.io/nasa/harmony-opendap-subsetter` to perform HOSS operations and extract a rectangular portion of the x, y grid. There will be pixels requiring filling in this output.\n",
    "  * `ghcr.io/nasa/harmony-maskfill` to fill any pixels in the rectangular array segment, but outside the bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the request:\n",
    "bbox_subset_request = Request(collection=collection, spatial=bounding_box, max_results=1)\n",
    "\n",
    "# Submit the request and download the results\n",
    "bbox_subset_job_id = harmony_client.submit(bbox_subset_request)\n",
    "harmony_client.wait_for_processing(bbox_subset_job_id, show_progress=True)\n",
    "bbox_subset_outputs = [file_future.result()\n",
    "                       for file_future\n",
    "                       in harmony_client.download_all(bbox_subset_job_id, overwrite=True)]\n",
    "\n",
    "replace(bbox_subset_outputs[0], 'hoss_bbox_subset.nc4')\n",
    "\n",
    "# Inspect the results:\n",
    "with xr.open_dataset('hoss_bbox_subset.nc4', group=variable_group) as dataset:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72279cbc",
   "metadata": {},
   "source": [
    "### A polygon spatial subset:\n",
    "\n",
    "This request will limit the spatial extent of the returned output. This request will be fulfilled using three steps. This can be observed via the `/workflow-ui` endpoint of Harmony.\n",
    "\n",
    "* `query-cmr` to filter granules to those with matching spatial coverage.\n",
    "* `ghcr.io/nasa/harmony-opendap-subsetter` to perform HOSS operations and extract a rectangular portion of the longitude latitude grid. This will minimally encompass the user-defined GeoJSON shape.\n",
    "* `ghcr.io/nasa/harmony-maskfill` to fill any pixels in the rectangular array segment, but outside the GeoJSON shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf60e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the request:\n",
    "shape_file_subset_request = Request(collection=collection, shape='shape_files/bermuda_triangle.geo.json', max_results=1)\n",
    "\n",
    "# Submit the request and download the results\n",
    "shape_file_subset_job_id = harmony_client.submit(shape_file_subset_request)\n",
    "harmony_client.wait_for_processing(shape_file_subset_job_id, show_progress=True)\n",
    "shape_file_subset_outputs = [file_future.result()\n",
    "                             for file_future\n",
    "                             in harmony_client.download_all(shape_file_subset_job_id, overwrite=True)]\n",
    "\n",
    "replace(shape_file_subset_outputs[0], 'hoss_shape_file_subset.nc4')\n",
    "# Inspect the results:\n",
    "with xr.open_dataset('hoss_shape_file_subset.nc4', group=variable_group) as dataset:\n",
    "    print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
